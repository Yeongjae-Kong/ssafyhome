import os
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from fastapi.middleware.cors import CORSMiddleware
from dotenv import load_dotenv

# [ê¸°ì¡´] ë¬¸ì„œ ë¡œë” ë° ë¶„í• ê¸°
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_chroma import Chroma
from langchain_core.prompts import ChatPromptTemplate

# LangChain v1.0 í˜¸í™˜ì„± ì²˜ë¦¬
try:
    from langchain_classic.chains import create_retrieval_chain
    from langchain_classic.chains.combine_documents import create_stuff_documents_chain
except ImportError:
    from langchain.chains import create_retrieval_chain
    from langchain.chains.combine_documents import create_stuff_documents_chain

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ (.env íŒŒì¼ì— GMS KEYê°€ OPENAI_API_KEYë¡œ ì €ì¥ë˜ì–´ ìˆì–´ì•¼ í•¨)
load_dotenv()

app = FastAPI()

# 1. CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# 2. ì „ì—­ ë³€ìˆ˜
vector_store = None
rag_chain = None 

# [â˜…í•µì‹¬ ìˆ˜ì • 1] SSAFY GMS Base URL ì •ì˜
SSAFY_GMS_BASE_URL = "https://gms.ssafy.io/gmsapi/api.openai.com/v1"

@app.on_event("startup")
async def startup_event():
    global vector_store, rag_chain
    
    pdf_path = "report.pdf"
    
    if not os.path.exists(pdf_path):
        print(f"âš ï¸  íŒŒì¼ ì—†ìŒ: {pdf_path} (RAG ê¸°ëŠ¥ ë¶ˆê°€)")
        return

    print("ğŸ“„ PDF ë¡œë”© ë° ë²¡í„° DB êµ¬ì¶• ì‹œì‘...")
    
    # PDF ë¡œë“œ & ë¶„í• 
    loader = PyPDFLoader(pdf_path)
    documents = loader.load()
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    splits = text_splitter.split_documents(documents)
    
    # [í•µì‹¬ ìˆ˜ì •] chunk_size=10 ì¶”ê°€
    # ì´ë ‡ê²Œ í•˜ë©´ ë¬¸ì„œë¥¼ 10ê°œì”© ëŠì–´ì„œ GMSë¡œ ë³´ë‚´ë¯€ë¡œ 413 ì—ëŸ¬ê°€ ë°œìƒí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    embedding_model = OpenAIEmbeddings(
        model="text-embedding-3-small", # í˜¹ì€ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ëª…
        base_url=SSAFY_GMS_BASE_URL,
        chunk_size=10  # â˜… ì¤‘ìš”: í•œ ë²ˆì˜ ìš”ì²­ì— í¬í•¨í•  í…ìŠ¤íŠ¸ ì²­í¬ ê°œìˆ˜ ì œí•œ
    )

    vector_store = Chroma.from_documents(
        documents=splits, 
        embedding=embedding_model
    )
    # [â˜…í•µì‹¬ ìˆ˜ì • 3] LLMì— GMS Base URL ì ìš©
    # model_nameì€ GMSì—ì„œ ì§€ì›í•˜ëŠ” ëª¨ë¸ëª…(ì˜ˆ: gpt-4o, gpt-4.1 ë“±)ìœ¼ë¡œ ë§ì¶°ì£¼ì„¸ìš”.
    llm = ChatOpenAI(
        model_name="gpt-4o", 
        temperature=0,
        base_url=SSAFY_GMS_BASE_URL
    )
    
    retriever = vector_store.as_retriever(search_kwargs={"k": 3})
    
    # 1) ì§ˆë¬¸-ë‹µë³€ í”„ë¡¬í”„íŠ¸ ì •ì˜
    system_prompt = (
        "ë‹¹ì‹ ì€ ë¶€ë™ì‚° ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ì˜ [Context]ë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”."
        "ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì§€ì–´ë‚´ì§€ ë§ê³  ëª¨ë¥¸ë‹¤ê³  ë‹µí•˜ì„¸ìš”."
        "\n\n"
        "[Context]:\n{context}"
    )
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("human", "{input}"),
    ])

    # 2) ë¬¸ì„œ ê²°í•© ì²´ì¸ ìƒì„±
    question_answer_chain = create_stuff_documents_chain(llm, prompt)
    
    # 3) ìµœì¢… ê²€ìƒ‰ ì²´ì¸ ìƒì„±
    rag_chain = create_retrieval_chain(retriever, question_answer_chain)
    
    print("âœ… RAG ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ! (SSAFY GMS Connected)")

class AnalyzeRequest(BaseModel):
    region: str
    query: str = ""

@app.post("/api/rag/analyze")
async def analyze_real_estate(req: AnalyzeRequest):
    if not rag_chain:
        raise HTTPException(status_code=500, detail="RAG ì„œë²„ ì´ˆê¸°í™” ì‹¤íŒ¨ (PDF í™•ì¸ ìš”ë§)")
    
    # ì§ˆë¬¸ êµ¬ì„±
    user_input = f"{req.region} ì§€ì—­ì˜ 2025ë…„ ë¶€ë™ì‚° ì‹œì¥ ì „ë§ì— ëŒ€í•´ ë³´ê³ ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ìì„¸íˆ ë¶„ì„í•´ì¤˜. {req.query}"
    
    try:
        # ì‹¤í–‰
        response = rag_chain.invoke({"input": user_input})
        return {"result": response["answer"]}
        
    except Exception as e:
        print(f"Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    # ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš© ì‹¤í–‰
    uvicorn.run(app, host="0.0.0.0", port=8000)